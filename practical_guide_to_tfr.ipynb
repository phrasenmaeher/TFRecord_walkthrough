{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "practical_guide_to_tfr.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phrasenmaeher/TFRecord_walkthrough/blob/main/practical_guide_to_tfr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bhw2-h9P2-sY"
      },
      "source": [
        "# A practical introduction to TFRecords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1cXAR-k3AgO"
      },
      "source": [
        "This notebook explains how to create TFRecord files for various data types. It contains the code for the post at [TDS](https://towardsdatascience.com/a-practical-guide-to-tfrecords-584536bc786c)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxNmtc-Y22xl"
      },
      "source": [
        "## Imports and helper functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1j71h5R3MaD"
      },
      "source": [
        "Let's start by importing our required packages, TensorFlow and Numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaNQp2is27rQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import librosa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k1bvWZY3Tt1"
      },
      "source": [
        "Next we need to define four small helper functions that hold the features that we'll store in our TFRecord files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUVrG0jA29O9"
      },
      "source": [
        "def _bytes_feature(value):\n",
        "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "    if isinstance(value, type(tf.constant(0))): # if value ist tensor\n",
        "        value = value.numpy() # get value of tensor\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a floast_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def serialize_array(array):\n",
        "  array = tf.io.serialize_tensor(array)\n",
        "  return array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9m5GJcc3tDD"
      },
      "source": [
        "## Image data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQJE84M29xKM"
      },
      "source": [
        "### A couple of images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APIBqxc43uvJ"
      },
      "source": [
        "This section assumes that you want to write image data to your disk. Rather than dowloading some image datasets, we'll create reasonably shaped numpy arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmBIr5IN3erZ"
      },
      "source": [
        "image_small_shape = (250,250,3)\n",
        "number_of_images_small = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8XsnMau37TL",
        "outputId": "3410a53c-cb4c-4632-d79a-e333addad2bd"
      },
      "source": [
        "images_small = np.random.randint(low=0, high=256, size=(number_of_images_small, *image_small_shape), dtype=np.int16)\n",
        "print(images_small.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 250, 250, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HiiQVl04cbJ"
      },
      "source": [
        "Now we create some random labels, and inspect them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qlz-MwW4MJe",
        "outputId": "f66013a8-92f4-4113-865c-f570ba91dabe"
      },
      "source": [
        "labels_small = np.random.randint(low=0, high=5, size=(number_of_images_small, 1))\n",
        "print(labels_small.shape)\n",
        "print(labels_small[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 1)\n",
            "[[2]\n",
            " [4]\n",
            " [3]\n",
            " [3]\n",
            " [2]\n",
            " [4]\n",
            " [2]\n",
            " [3]\n",
            " [3]\n",
            " [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IVHj_jB7dSu"
      },
      "source": [
        "Define our function to write the image data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DpkFDgDhMxN"
      },
      "source": [
        "def parse_single_image(image, label):\n",
        "  \n",
        "  #define the dictionary -- the structure -- of our single example\n",
        "  data = {\n",
        "        'height' : _int64_feature(image.shape[0]),\n",
        "        'width' : _int64_feature(image.shape[1]),\n",
        "        'depth' : _int64_feature(image.shape[2]),\n",
        "        'raw_image' : _bytes_feature(serialize_array(image)),\n",
        "        'label' : _int64_feature(label)\n",
        "    }\n",
        "  \n",
        "  #create an Example, wrapping the single features\n",
        "  out = tf.train.Example(features=tf.train.Features(feature=data))\n",
        "\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_wj4lPH4rBQ"
      },
      "source": [
        "def write_images_to_tfr_short(images, labels, filename:str=\"images\"):\n",
        "  filename= filename+\".tfrecords\"\n",
        "  writer = tf.io.TFRecordWriter(filename) #create a writer that'll store our data to disk\n",
        "  count = 0\n",
        "\n",
        "  for index in range(len(images)):\n",
        "\n",
        "    #get the data we want to write\n",
        "    current_image = images[index] \n",
        "    current_label = labels[index]\n",
        "\n",
        "    #define the dictionary -- the structure -- of our single example\n",
        "    out = parse_single_image(image=current_image, label=current_label)\n",
        "    writer.write(out.SerializeToString())\n",
        "    count += 1\n",
        "\n",
        "  writer.close()\n",
        "  print(f\"Wrote {count} elements to TFRecord\")\n",
        "  return count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXMDfaQ56rct"
      },
      "source": [
        "count = write_images_to_tfr_short(images_small, labels_small, filename=\"small_images\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmTv61HFAv57"
      },
      "source": [
        "def parse_tfr_element(element):\n",
        "  #use the same structure as above; it's kinda an outline of the structure we now want to create\n",
        "  data = {\n",
        "      'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "      'width':tf.io.FixedLenFeature([], tf.int64),\n",
        "      'label':tf.io.FixedLenFeature([], tf.int64),\n",
        "      'raw_image' : tf.io.FixedLenFeature([], tf.string),\n",
        "      'depth':tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "\n",
        "    \n",
        "  content = tf.io.parse_single_example(element, data)\n",
        "  \n",
        "  height = content['height']\n",
        "  width = content['width']\n",
        "  depth = content['depth']\n",
        "  label = content['label']\n",
        "  raw_image = content['raw_image']\n",
        "  \n",
        "  \n",
        "  #get our 'feature'-- our image -- and reshape it appropriately\n",
        "  feature = tf.io.parse_tensor(raw_image, out_type=tf.int16)\n",
        "  feature = tf.reshape(feature, shape=[height,width,depth])\n",
        "  return (feature, label)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbhOMVztBviJ"
      },
      "source": [
        "def get_dataset_small(filename):\n",
        "  #create the dataset\n",
        "  dataset = tf.data.TFRecordDataset(filename)\n",
        "\n",
        "  #pass every single feature through our mapping function\n",
        "  dataset = dataset.map(\n",
        "      parse_tfr_element\n",
        "  )\n",
        "    \n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eqw45UwXCPyf"
      },
      "source": [
        "dataset_small = get_dataset_small(\"/content/small_images.tfrecords\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyqZbeY8CgyM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31ae4b95-7130-4f85-80f9-6ea4a811f991"
      },
      "source": [
        "for sample in dataset_small.take(1):\n",
        "  print(sample[0].shape)\n",
        "  print(sample[1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(250, 250, 3)\n",
            "()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP-fO-mt91sB"
      },
      "source": [
        "### More than a couple of images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_otrDeg7hSG"
      },
      "source": [
        "Now, what would we do if we had not 100, but 50000 images, of larger shape? They do fit into a single file--but then we would have one large file. In their docs, TF encourages to shard the data across multiple files to enable parallel I/O. Secondly, one shard should be larger than 100 MB. Let's see how we can do this!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siMYOTUg-D0k"
      },
      "source": [
        "import tqdm\n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXaOq9dZ_iUl"
      },
      "source": [
        "image_large_shape = (400,750,3)\n",
        "number_of_images_large = 500 #constraining to 500 files here, to not outgrow RAM capacities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpAmPmsU_iUm",
        "outputId": "a4f4ae23-cfdb-4ce0-9e9f-32def8c42dc3"
      },
      "source": [
        "images_large = np.random.randint(low=0, high=256, size=(number_of_images_large, *image_large_shape), dtype=np.int16)\n",
        "print(images_large.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 400, 750, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MXqRLib_iUp"
      },
      "source": [
        "Now we create some random labels, and inspect them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HY6hipxP_iUq",
        "outputId": "0ad35fdf-6786-4c9b-d768-c052b31dc43c"
      },
      "source": [
        "labels_large = np.random.randint(low=0, high=5, size=(number_of_images_large, 1))\n",
        "print(labels_large.shape)\n",
        "print(labels_large[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 1)\n",
            "[[3]\n",
            " [1]\n",
            " [3]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [3]\n",
            " [4]\n",
            " [3]\n",
            " [1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBR2vddF6unL"
      },
      "source": [
        "def write_images_to_tfr_long(images, labels, filename:str=\"large_images\", max_files:int=10, out_dir:str=\"/content/\"):\n",
        "\n",
        "  #determine the number of shards (single TFRecord files) we need:\n",
        "  splits = (len(images)//max_files) + 1 #determine how many tfr shards are needed\n",
        "  if len(images)%max_files == 0:\n",
        "    splits-=1\n",
        "  print(f\"\\nUsing {splits} shard(s) for {len(images)} files, with up to {max_files} samples per shard\")\n",
        "\n",
        "  file_count = 0\n",
        "\n",
        "  for i in tqdm.tqdm(range(splits)):\n",
        "    current_shard_name = \"{}{}_{}{}.tfrecords\".format(out_dir, i+1, splits, filename)\n",
        "    writer = tf.io.TFRecordWriter(current_shard_name)\n",
        "\n",
        "    current_shard_count = 0\n",
        "    while current_shard_count < max_files: #as long as our shard is not full\n",
        "      #get the index of the file that we want to parse now\n",
        "      index = i*max_files+current_shard_count\n",
        "      if index == len(images): #when we have consumed the whole data, preempt generation\n",
        "        break\n",
        "      \n",
        "      current_image = images[index]\n",
        "      current_label = labels[index]\n",
        "\n",
        "      #create the required Example representation\n",
        "      out = parse_single_image(image=current_image, label=current_label)\n",
        "    \n",
        "      writer.write(out.SerializeToString())\n",
        "      current_shard_count+=1\n",
        "      file_count += 1\n",
        "\n",
        "    writer.close()\n",
        "  print(f\"\\nWrote {file_count} elements to TFRecord\")\n",
        "  return file_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KblrXi09pno"
      },
      "source": [
        "write_images_to_tfr_long(images_large, labels_large, max_files=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCA8LFkF_e-4"
      },
      "source": [
        "def get_dataset_large(tfr_dir:str=\"/content/\", pattern:str=\"*large_images.tfrecords\"):\n",
        "    files = glob.glob(tfr_dir+pattern, recursive=False)\n",
        "\n",
        "    #create the dataset\n",
        "    dataset = tf.data.TFRecordDataset(files)\n",
        "\n",
        "    #pass every single feature through our mapping function\n",
        "    dataset = dataset.map(\n",
        "        parse_tfr_element\n",
        "    )\n",
        "    \n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuqeoNJHiqU2"
      },
      "source": [
        "dataset_large = get_dataset_large()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJoG-p-jjeKh"
      },
      "source": [
        "for sample in dataset_large.take(1):\n",
        "  print(sample[0].shape)\n",
        "  print(sample[1].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXcdGdeol1By"
      },
      "source": [
        "## Audio data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1xmMVkumSSV"
      },
      "source": [
        "Let's construct an artificial dataset first:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtpUb035l2YW"
      },
      "source": [
        "import librosa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ekjzjlVqn5M"
      },
      "source": [
        "The audio samples are of different length. But that's not of concern, TFRecords naturally support this case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-8zJIn4mkdR"
      },
      "source": [
        "def create_dummy_audio_dataset():\n",
        "  files = []\n",
        "  labels = []\n",
        "\n",
        "  for i in range(100):\n",
        "    if i %2==0:\n",
        "      filename = librosa.ex('fishin')\n",
        "      labels.append(0)\n",
        "    if i %3==0:\n",
        "      filename = librosa.ex('brahms')\n",
        "      labels.append(1)\n",
        "    if i %5==0:\n",
        "      filename = librosa.ex('nutcracker')\n",
        "      labels.append(2)\n",
        "    if i %7==0:\n",
        "      filename = librosa.ex('trumpet')\n",
        "      labels.append(3)\n",
        "    else:\n",
        "      filename = librosa.ex('vibeace')\n",
        "      labels.append(4)\n",
        "    \n",
        "    y, sr = librosa.load(filename)\n",
        "    files.append([y, sr])\n",
        "  return files, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki1lOoJDnjk8"
      },
      "source": [
        "def parse_single_audio_file(audio, label):\n",
        "\n",
        "  data = {\n",
        "        'sr' : _int64_feature(audio[1]),\n",
        "        'len' : _int64_feature(len(audio[0])),\n",
        "        'y' : _bytes_feature(serialize_array(audio[0])),\n",
        "        'label' : _int64_feature(label)\n",
        "    }\n",
        "  \n",
        "  out = tf.train.Example(features=tf.train.Features(feature=data))\n",
        "\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLgcoJNinjk-"
      },
      "source": [
        "def write_audio_to_tfr(audios, labels, filename:str=\"audio\"):\n",
        "  filename= filename+\".tfrecords\"\n",
        "  writer = tf.io.TFRecordWriter(filename) #create a writer that'll store our data to disk\n",
        "  count = 0\n",
        "\n",
        "  for index in range(len(audios)):\n",
        "\n",
        "    #get the data we want to write\n",
        "    current_audio = audios[index] \n",
        "    current_label = labels[index]\n",
        "\n",
        "    #define the dictionary -- the structure -- of our single example\n",
        "    out = parse_single_audio_file(audio=current_audio, label=current_label)\n",
        "    writer.write(out.SerializeToString())\n",
        "    count += 1\n",
        "\n",
        "  writer.close()\n",
        "  print(f\"Wrote {count} elements to TFRecord\")\n",
        "  return count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDPYMpJNh1b2"
      },
      "source": [
        "audios, labels = create_dummy_audio_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kf3-Dvbn_Wd"
      },
      "source": [
        "write_audio_to_tfr(audios, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8qVAuREosi8"
      },
      "source": [
        "def parse_tfr_audio_element(element):\n",
        "  #use the same structure as above; it's kinda an outline of the structure we now want to create\n",
        "\n",
        "  data = {\n",
        "      'sr': tf.io.FixedLenFeature([], tf.int64),\n",
        "      'len':tf.io.FixedLenFeature([], tf.int64),\n",
        "      'y' : tf.io.FixedLenFeature([], tf.string),\n",
        "      'label':tf.io.FixedLenFeature([], tf.int64),\n",
        "      \n",
        "    }\n",
        "  \n",
        "  content = tf.io.parse_single_example(element, data)\n",
        "  \n",
        "  sr = content['sr']\n",
        "  len = content['len']\n",
        "  y = content['y']\n",
        "  label = content['label']\n",
        "  \n",
        "  \n",
        "  #get our 'feature'-- our image -- and reshape it appropriately\n",
        "  feature = tf.io.parse_tensor(y, out_type=tf.float32)\n",
        "  feature = tf.reshape(feature, shape=[len])\n",
        "  return (feature, label)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r27euhXol4B"
      },
      "source": [
        "def get_audio_dataset(filename):\n",
        "  #create the dataset\n",
        "  dataset = tf.data.TFRecordDataset(filename)\n",
        "\n",
        "  #pass every single feature through our mapping function\n",
        "  dataset = dataset.map(\n",
        "      parse_tfr_audio_element\n",
        "  )\n",
        "    \n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daErq_IAol4D"
      },
      "source": [
        "dataset_audio = get_audio_dataset(\"/content/audio.tfrecords\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jebRBb07ol4E"
      },
      "source": [
        "for sample in dataset_audio.take(1):\n",
        "  print(sample[0].shape) #the audio data\n",
        "  print(sample[1]) #the label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq6Pt1z-jHFM"
      },
      "source": [
        "## Text data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmWGL5twjMO3"
      },
      "source": [
        "So far we have worked with numerical data only: Both the images and the audio files were repesentated as float values. For the following example, let's cover the third large domain: Text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EuG4HrVq3KV"
      },
      "source": [
        "def create_dummy_text_dataset(size:int=100):\n",
        "  text_data = []\n",
        "  labels = []\n",
        "\n",
        "  for i in range(size):\n",
        "    if i % 2 == 0:\n",
        "      text = \"Hey, this is a sample text. We can use many different symbols.\"\n",
        "      label = 0\n",
        "    else:\n",
        "      text = \"A point is exactly what the folks think of it; after Gauss.\"\n",
        "      label = 1\n",
        "    text_data.append(text)\n",
        "    labels.append(label)\n",
        "  \n",
        "  return text_data, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izRDGznTkcry"
      },
      "source": [
        "def parse_single_text_data(text, label):\n",
        "\n",
        "  data = {\n",
        "        'text' : _bytes_feature(serialize_array(text)),\n",
        "        'label' : _int64_feature(label)\n",
        "    }\n",
        "  \n",
        "  out = tf.train.Example(features=tf.train.Features(feature=data))\n",
        "\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUfB7YJ1lMT6"
      },
      "source": [
        "def write_text_to_tfr(text_data, labels, filename:str=\"text\"):\n",
        "  filename= filename+\".tfrecords\"\n",
        "  writer = tf.io.TFRecordWriter(filename) #create a writer that'll store our text data to disk\n",
        "  count = 0\n",
        "\n",
        "  for index in range(len(text_data)):\n",
        "\n",
        "    #get the data we want to write\n",
        "    current_text = text_data[index] \n",
        "    current_label = labels[index]\n",
        "\n",
        "    #define the dictionary -- the structure -- of our single example\n",
        "    out = parse_single_text_data(text=current_text, label=current_label)\n",
        "    writer.write(out.SerializeToString())\n",
        "    count += 1\n",
        "\n",
        "  writer.close()\n",
        "  print(f\"Wrote {count} elements to TFRecord\")\n",
        "  return count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ozMgx8ElcMl"
      },
      "source": [
        "text, labels = create_dummy_text_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_E_C_NGleib",
        "outputId": "e42ec7ab-c04b-4f61-98ee-e7e368157891"
      },
      "source": [
        "text[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hey, this is a sample text. We can use many different symbols.',\n",
              " 'A point is exactly what the folks think of it; after Gauss.',\n",
              " 'Hey, this is a sample text. We can use many different symbols.',\n",
              " 'A point is exactly what the folks think of it; after Gauss.',\n",
              " 'Hey, this is a sample text. We can use many different symbols.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5uXlQeelfip"
      },
      "source": [
        "write_text_to_tfr(text_data=text, labels=labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li7msiIkmDaW"
      },
      "source": [
        "def parse_tfr_text_element(element):\n",
        "  #use the same structure as above; it's kinda an outline of the structure we now want to create\n",
        "  \n",
        "  data = {\n",
        "      'text' : tf.io.FixedLenFeature([], tf.string),\n",
        "      'label':tf.io.FixedLenFeature([], tf.int64),\n",
        "      \n",
        "    }\n",
        "  \n",
        "  content = tf.io.parse_single_example(element, data)\n",
        "  \n",
        "  text = content['text']\n",
        "  label = content['label']\n",
        "  \n",
        "  #get our 'feature', our text data\n",
        "  feature = tf.io.parse_tensor(text, out_type=tf.string)\n",
        "  return (feature, label)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvK4sY4Lmfrk"
      },
      "source": [
        "def get_text_dataset(filename):\n",
        "  #create the dataset\n",
        "  dataset = tf.data.TFRecordDataset(filename)\n",
        "\n",
        "  #pass every single feature through our mapping function\n",
        "  dataset = dataset.map(\n",
        "      parse_tfr_text_element\n",
        "  )\n",
        "    \n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9OIkr9umi-z"
      },
      "source": [
        "text_dataset = get_text_dataset(\"/content/text.tfrecords\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KwR2-iMmqVx",
        "outputId": "85b0a4ea-4244-4818-a5df-f7652797346b"
      },
      "source": [
        "for sample in text_dataset.take(2):\n",
        "  print(sample[0].numpy()) #the text data\n",
        "  print(sample[1]) #the label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Hey, this is a sample text. We can use many different symbols.'\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "b'A point is exactly what the folks think of it; after Gauss.'\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beILMp58mx24"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGNRwNJHnHBg"
      },
      "source": [
        "## Multiple data types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwhxOl8hnJ5A"
      },
      "source": [
        "We have examined single single domains until now. Of course, there's nothing that speaks agains combining multiple domains! For the following, consider this outline:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uIzz3emnaad"
      },
      "source": [
        "We have multiple images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0XVVyN3nJI_",
        "outputId": "e1779a87-c4cb-498b-f363-b4693cdfd303"
      },
      "source": [
        "images_shape = (256, 256, 3)\n",
        "size = 100\n",
        "images_combined = np.random.randint(low=0, high=256, size=(100, *images_shape), dtype=np.int16)\n",
        "print(images_combined.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 256, 256, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2zok7cgn1wD"
      },
      "source": [
        "Secondly, we have a short description of each image, describing the scenery that the images shows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR2BQcltoC63"
      },
      "source": [
        "def create_dummy_text_dataset_combined(size:int=100):\n",
        "  text_data = []\n",
        "  labels = []\n",
        "\n",
        "  for i in range(size):\n",
        "    if i %2==0:\n",
        "      text = \"This image shows a wooden bridge. It connects South Darmian with the norther parts of Frenklund.\"\n",
        "      label = 0\n",
        "    if i %3==0:\n",
        "      text = \"This image shows a sun flower. It's leaves are green, the petals are of strong yellow\"\n",
        "      label = 1\n",
        "    if i %5==0:\n",
        "      text = \"This image shows five children playing in the sandbox. They are laughing\"\n",
        "      label = 2\n",
        "    if i %7==0:\n",
        "      text = \"This image shows a house on a cliff. The house is painted in red and brown tones.\"\n",
        "      label = 3\n",
        "    else:\n",
        "      text = \"This image shows a horse and a zebra. They come from a CycleGAN.\"\n",
        "      label = 4\n",
        "  \n",
        "    text_data.append(text)\n",
        "    labels.append(label)\n",
        "  \n",
        "  return text_data, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq4NhmxwnvpL"
      },
      "source": [
        "text, text_labels = create_dummy_text_dataset_combined()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ihXvAX0pXzk"
      },
      "source": [
        "Lastly, we also have an auditive description of the scenery. We'll reuse the dummy audio data from above:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRpZldHbpPEi"
      },
      "source": [
        "def create_dummy_audio_dataset(size:int=100):\n",
        "  files = []\n",
        "  labels = []\n",
        "\n",
        "  for i in range(size):\n",
        "    if i %2==0:\n",
        "      filename = librosa.ex('fishin')\n",
        "      labels.append(0)\n",
        "    if i %3==0:\n",
        "      filename = librosa.ex('brahms')\n",
        "      labels.append(1)\n",
        "    if i %5==0:\n",
        "      filename = librosa.ex('nutcracker')\n",
        "      labels.append(2)\n",
        "    if i %7==0:\n",
        "      filename = librosa.ex('trumpet')\n",
        "      labels.append(3)\n",
        "    else:\n",
        "      filename = librosa.ex('vibeace')\n",
        "      labels.append(4)\n",
        "    \n",
        "    y, sr = librosa.load(filename)\n",
        "    files.append([y, sr])\n",
        "  return files, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtvQ2SyQrLLB",
        "outputId": "a08eeb52-5644-43ce-dc97-191e14665c82"
      },
      "source": [
        "audio, audio_labels = create_dummy_audio_dataset()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading file 'Karissa_Hobbs_-_Let's_Go_Fishin'.ogg' from 'https://librosa.org/data/audio/Karissa_Hobbs_-_Let's_Go_Fishin'.ogg' to '/root/.cache/librosa'.\n",
            "Downloading file 'Hungarian_Dance_number_5_-_Allegro_in_F_sharp_minor_(string_orchestra).ogg' from 'https://librosa.org/data/audio/Hungarian_Dance_number_5_-_Allegro_in_F_sharp_minor_(string_orchestra).ogg' to '/root/.cache/librosa'.\n",
            "Downloading file 'Kevin_MacLeod_-_P_I_Tchaikovsky_Dance_of_the_Sugar_Plum_Fairy.ogg' from 'https://librosa.org/data/audio/Kevin_MacLeod_-_P_I_Tchaikovsky_Dance_of_the_Sugar_Plum_Fairy.ogg' to '/root/.cache/librosa'.\n",
            "Downloading file 'sorohanro_-_solo-trumpet-06.ogg' from 'https://librosa.org/data/audio/sorohanro_-_solo-trumpet-06.ogg' to '/root/.cache/librosa'.\n",
            "Downloading file 'Kevin_MacLeod_-_Vibe_Ace.ogg' from 'https://librosa.org/data/audio/Kevin_MacLeod_-_Vibe_Ace.ogg' to '/root/.cache/librosa'.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWOl7uY7poyM"
      },
      "source": [
        "Now, let's combine them into the TFRecord files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADjZm8jzpnjb"
      },
      "source": [
        "def parse_combined_data(image, text, text_label, audio, audio_label):\n",
        "\n",
        "  data = {\n",
        "        #for the image\n",
        "        'height' : _int64_feature(image.shape[0]),\n",
        "        'width' : _int64_feature(image.shape[1]),\n",
        "        'depth' : _int64_feature(image.shape[2]),\n",
        "        'raw_image' : _bytes_feature(serialize_array(image)),\n",
        "        #for the text\n",
        "        'text' : _bytes_feature(serialize_array(text)),\n",
        "        'text_label' : _int64_feature(text_label),\n",
        "        #for the audio\n",
        "        'sr' : _int64_feature(audio[1]),\n",
        "        'len' : _int64_feature(len(audio[0])),\n",
        "        'y' : _bytes_feature(serialize_array(audio[0])),\n",
        "        'audio_label' : _int64_feature(audio_label)\n",
        "    }\n",
        "  \n",
        "  out = tf.train.Example(features=tf.train.Features(feature=data))\n",
        "\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv6ufSY0qdlw"
      },
      "source": [
        "def write_combined_data_to_tfr(images, text_data, text_labels, audio_data, audio_labels, filename:str=\"combined\"):\n",
        "  filename= filename+\".tfrecords\"\n",
        "  writer = tf.io.TFRecordWriter(filename) #create a writer that'll store our text data to disk\n",
        "  count = 0\n",
        "\n",
        "  for index in range(len(images)):\n",
        "    \n",
        "    #get the image data\n",
        "    current_image = images[index]\n",
        "\n",
        "    #get the text data\n",
        "    current_text = text_data[index] \n",
        "    current_text_label = text_labels[index]\n",
        "\n",
        "    #get the audio data\n",
        "    current_audio = audio_data[index]\n",
        "    current_audio_label = audio_labels[index]\n",
        "\n",
        "    out = parse_combined_data(image=current_image, text=current_text, text_label=current_text_label, audio=current_audio, audio_label=current_audio_label)\n",
        "    writer.write(out.SerializeToString())\n",
        "    count += 1\n",
        "\n",
        "  writer.close()\n",
        "  print(f\"Wrote {count} elements to TFRecord\")\n",
        "  return count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwIJ0_-prI7I",
        "outputId": "af7c7ac2-629d-4d47-c3c9-b4a4d87d5006"
      },
      "source": [
        "write_combined_data_to_tfr(images=images_combined, text_data=text, text_labels=text_labels, audio_data=audio, audio_labels=audio_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrote 100 elements to TFRecord\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHr9lAknrkuL"
      },
      "source": [
        "def parse_combined_tfr_element(element):\n",
        "  #use the same structure as above; it's kinda an outline of the structure we now want to create\n",
        "  data = {\n",
        "      #for the images\n",
        "      'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "      'width':tf.io.FixedLenFeature([], tf.int64),\n",
        "      'raw_image' : tf.io.FixedLenFeature([], tf.string),\n",
        "      'depth':tf.io.FixedLenFeature([], tf.int64),\n",
        "      #for the text\n",
        "      'text' : tf.io.FixedLenFeature([], tf.string),\n",
        "      'text_label':tf.io.FixedLenFeature([], tf.int64),\n",
        "      #for the audio\n",
        "      'sr': tf.io.FixedLenFeature([], tf.int64),\n",
        "      'len':tf.io.FixedLenFeature([], tf.int64),\n",
        "      'y' : tf.io.FixedLenFeature([], tf.string),\n",
        "      'audio_label':tf.io.FixedLenFeature([], tf.int64),\n",
        "      \n",
        "    }\n",
        "  \n",
        "  content = tf.io.parse_single_example(element, data)\n",
        "\n",
        "  #image data\n",
        "  height = content['height']\n",
        "  width = content['width']\n",
        "  depth = content['depth']\n",
        "  raw_image = content['raw_image']\n",
        "  \n",
        "  image_feature = tf.io.parse_tensor(raw_image, out_type=tf.int16)\n",
        "  image_feature = tf.reshape(image_feature, shape=[height,width,depth])\n",
        "  \n",
        "  #audio data\n",
        "  sr = content['sr']\n",
        "  len = content['len']\n",
        "  y = content['y']\n",
        "  audio_label = content['audio_label']\n",
        "\n",
        "  audio_feature = tf.io.parse_tensor(y, out_type=tf.float32)\n",
        "  audio_feature = tf.reshape(audio_feature, shape=[len])\n",
        "\n",
        "  \n",
        "  #text data\n",
        "  text = content['text']\n",
        "  text_label = content['text_label']\n",
        "  \n",
        "  text_feature = tf.io.parse_tensor(text, out_type=tf.string)\n",
        "\n",
        "  \n",
        "  return image_feature, text_feature, text_label, audio_feature, audio_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j8XdwhIqk5T"
      },
      "source": [
        "def get_combined_dataset(filename):\n",
        "  #create the dataset\n",
        "  dataset = tf.data.TFRecordDataset(filename)\n",
        "\n",
        "  #pass every single feature through our mapping function\n",
        "  dataset = dataset.map(\n",
        "      parse_combined_tfr_element\n",
        "  )\n",
        "    \n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M-bg0skqk5V"
      },
      "source": [
        "ds = get_combined_dataset(\"/content/combined.tfrecords\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8WjTHlzs6Zm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4947428b-4798-4a01-faed-c03349558d6f"
      },
      "source": [
        "next(iter(ds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(256, 256, 3), dtype=int16, numpy=\n",
              " array([[[160, 224, 213],\n",
              "         [ 45, 231, 164],\n",
              "         [157, 167, 117],\n",
              "         ...,\n",
              "         [221,  46, 247],\n",
              "         [207,  30, 251],\n",
              "         [127, 133, 154]],\n",
              " \n",
              "        [[137, 211, 154],\n",
              "         [172, 160,  55],\n",
              "         [125, 171,  19],\n",
              "         ...,\n",
              "         [ 78,  10, 144],\n",
              "         [191, 131, 125],\n",
              "         [101,  32, 140]],\n",
              " \n",
              "        [[182, 191,  61],\n",
              "         [112, 247,  29],\n",
              "         [248, 203, 166],\n",
              "         ...,\n",
              "         [145,  91, 130],\n",
              "         [165, 108,  59],\n",
              "         [  6, 125,  19]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[169, 122, 229],\n",
              "         [160, 185, 109],\n",
              "         [ 29, 255, 210],\n",
              "         ...,\n",
              "         [129,  37, 226],\n",
              "         [194, 130,  64],\n",
              "         [126,  32, 218]],\n",
              " \n",
              "        [[193,  93, 110],\n",
              "         [ 15, 130,  75],\n",
              "         [122,  46,  23],\n",
              "         ...,\n",
              "         [ 72, 104, 223],\n",
              "         [253, 149,  46],\n",
              "         [123,  28,  44]],\n",
              " \n",
              "        [[163, 140,  96],\n",
              "         [146, 244, 244],\n",
              "         [109,  96,  92],\n",
              "         ...,\n",
              "         [243,  29, 158],\n",
              "         [162,  54, 155],\n",
              "         [189, 253,  65]]], dtype=int16)>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'This image shows a house on a cliff. The house is painted in red and brown tones.'>,\n",
              " <tf.Tensor: shape=(), dtype=int64, numpy=3>,\n",
              " <tf.Tensor: shape=(117601,), dtype=float32, numpy=\n",
              " array([-1.4068224e-03, -4.4607223e-04, -4.1098078e-04, ...,\n",
              "         7.9623060e-06, -3.0417003e-05,  1.2765067e-05], dtype=float32)>,\n",
              " <tf.Tensor: shape=(), dtype=int64, numpy=0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0xwqV7lq65I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}